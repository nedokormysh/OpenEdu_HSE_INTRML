{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nedokormysh/OpenEdu_HSE_INTRML/blob/week6/Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jSVwwV0ZSib"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyOBT_yuOPbt"
      },
      "source": [
        "## 20Newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pXEYBa1irKy"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kPs28eIizK7"
      },
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После того как мы загрузили обучающую и тестовую часть в newsgroups_train переменной и в newsgroups_test\n",
        "лежат словари, ключи этих словарей вы видите на экране. По ключу date лежат сами данные текстовые,\n",
        "по ключу target лежат метки классов."
      ],
      "metadata": {
        "id": "UFxmXlUQMwVv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TJi0Cpvi0GB",
        "outputId": "ec442d4c-9787-4b9f-b962-b7c667bf5649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "newsgroups_train.keys()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим то, как выглядит новостная статья. Возьмём вот\n",
        "какую-то одну новостную статью из обучающей выборки. Видно, что это какая-то короткая статья\n",
        "текстовая на английском языке. "
      ],
      "metadata": {
        "id": "GP6gcHNPMpYi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bS4nDRNi0Ju",
        "outputId": "59bdbebb-1432-4d6e-8123-6840eb3e3631",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (newsgroups_train.data[0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gyFClg2Oi3q"
      },
      "source": [
        "### 1. Предварительная обработка текста"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тексты на естественном языке могут содержать много слов, которые не\n",
        "несут никакой информации об этом тексте. Например, в русском языке к таким словам можно отнести\n",
        "предлоги, союзы, частицы, в английском языке к таким словам можно отнести артикли и обычно\n",
        "перед тем, как осуществлять классификацию текстов,такие слова удаляют из текста. Давайте удалим эти слова\n",
        "и осуществим какую-то простейшую предобработку нашего текста. Для этого напишем функцию\n",
        "preprocess_text, она будет принимать на вход список текстов. в этой функции сначала в переменную\n",
        "stop_word положим множество стоп-слов английского языка, это те слова как раз, которые\n",
        "не несут никакой информации, мы хотим их удалить. Эти слова мы получили из библиотеки nltk - это\n",
        "библиотека как раз для работы с текстами. Дальше в переменную regex сохраним регулярное выражение, и в\n",
        "переменную preprocess_text создадим пустой список в эту переменную, и в переменную preprocess_text\n",
        "будем как раскладывать передобработанные тексты. Далее пройдемся по всем текстам, приведем\n",
        "их к нижнему регистру с помощью метода lower, каждый текст применим регулярное выражение, то\n",
        "есть в этом регулярном выражении мы удалим все символы, которые не являются английскими буквами\n",
        "в верхнем или нижнем регистре. Дальше токенизируем наши тексты, то есть разобьем на слова\n",
        "и пройдемся по всем словам, и если эти слова находятся в списки стоп-слов, то удалим их, то\n",
        "есть не будем включать в результирующей список. И на выходе получим список с предобработанными\n",
        "текстами, текстами, которые будут приведены в нижний регистр, из этих текстов будут удалены все\n",
        "лишние символы, то есть останутся только символы из английского алфавита, и удалим все стоп-слова."
      ],
      "metadata": {
        "id": "bEL6er7tNQUU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLzaHw-_i0su",
        "outputId": "72c1e032-68cc-4d6e-c1d4-85d53d631898",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import tqdm\n",
        "\n",
        "\n",
        "def preprocess_text(texts):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    regex = re.compile('[^a-z A-Z]')\n",
        "    preprocess_texts = []\n",
        "    for i in  tqdm.tqdm(range(len(texts))):\n",
        "        text = texts[i].lower()\n",
        "        text = regex.sub(' ', text)\n",
        "        word_tokens = word_tokenize(text) \n",
        "        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
        "        preprocess_texts.append( ' '.join(filtered_sentence))\n",
        "    \n",
        "    return preprocess_texts"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-7Y15RKi0vg",
        "outputId": "8a669963-7873-4d75-81ef-ccb953d2f512",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "newsgroups_train['preprocess_data'] = preprocess_text(newsgroups_train.data)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11314/11314 [00:15<00:00, 726.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okehw7-zjIqK",
        "outputId": "1c5aa1f8-0d7f-4dd4-e666-8493d2e01be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "newsgroups_test['preprocess_data'] = preprocess_text(newsgroups_test.data)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7532/7532 [00:09<00:00, 766.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTWtrSHAjItA",
        "outputId": "ed21a016-3dd2-45da-ed94-9b1da7defbcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(newsgroups_train['preprocess_data'][0])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lerxst wam umd edu thing subject car nntp posting host rac wam umd edu organization university maryland college park lines wondering anyone could enlighten car saw day door sports car looked late early called bricklin doors really small addition front bumper separate rest body know anyone tellme model name engine specs years production car made history whatever info funky looking car please e mail thanks il brought neighborhood lerxst\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что текст полученный состоит только из английских букв, все эти буквы в нижнем\n",
        "регистре, ну и нет никаких артиклей, никаких стоп-слов. В текстах на естественном языке слова могут\n",
        "встречаться в разной форме, например, в русском языке одно и то же слово может встречаться в\n",
        "разных склонения, в единственном или в множественном числе, но при этом оно будет значить одно и то\n",
        "же, смысловая нагрузка этого слова будет одна и та же. "
      ],
      "metadata": {
        "id": "DUPEDzAYN3jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "И часто чтобы упростить задачу и даже\n",
        "иногда чтобы повысить качество решения нашей задачи, тексты применяется стемминг или лемматизация.\n",
        "Стемминг - это выделение основы слова у каждого слова в тексте. Лемматизация - это приведение\n",
        "каждого слова текста к начальной форме. Давайте применим к нашим текстам стемминг. Для этого из\n",
        "библиотеки nltk импортируем стеммер, напишем функцию stemming_text, который будет принимать на\n",
        "вход список текстов, и к каждому тексту применим, к каждому слову этого текста применим стеммер.\n",
        "То есть пройдемся циклом по всем текстам, токенизируем каждый текст, разобьем его на слова и каждому\n",
        "слову применим функцию стемминга. И на выходе функции stemming_text будет возвращать список\n",
        "текстов, в котором был применен стемминг к каждому слову. И применим функцию stemming_text\n",
        "к преобработанным данным на обучающей и на тестовое части. "
      ],
      "metadata": {
        "id": "rgYDFPJQOF_Q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZYKnEeYjIv1"
      },
      "source": [
        "from nltk.stem.lancaster import LancasterStemmer"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZCOP9HFjIyR"
      },
      "source": [
        "def stemming_texts(texts):\n",
        "  st = LancasterStemmer()\n",
        "  stem_text = []\n",
        "  for text in tqdm.tqdm(texts):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    stem_text.append(' '.join([st.stem(word) for word in word_tokens]))\n",
        "  return stem_text"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0h_D9xujI1E",
        "outputId": "375375dc-03ea-403b-90a7-a213e9d58faa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "newsgroups_train['data_stemming'] = \\\n",
        "                           stemming_texts(newsgroups_train.preprocess_data)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11314/11314 [00:43<00:00, 260.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IgwyKC0jI3g",
        "outputId": "f4cb5ba8-4767-4488-c797-9a8f5af305e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "newsgroups_test['data_stemming'] = \\\n",
        "                            stemming_texts(newsgroups_test.preprocess_data)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7532/7532 [00:25<00:00, 291.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "И посмотрим, что получилось,\n",
        "посмотрим, что было до применения стемминга и после применения стемминга. "
      ],
      "metadata": {
        "id": "Ft_u0JbEOoE5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0GU53hfjI6C",
        "outputId": "9b4ef632-caa6-49e0-dbf1-c108c9343f78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(newsgroups_train.data_stemming[0])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lerxst wam umd edu thing subject car nntp post host rac wam umd edu org univers maryland colleg park lin wond anyon could enlight car saw day door sport car look lat ear cal bricklin door real smal addit front bump sep rest body know anyon tellm model nam engin spec year produc car mad hist whatev info funky look car pleas e mail thank il brought neighb lerxst\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPpe-b5zvmUW",
        "outputId": "75428652-014f-4791-c6a5-8d78b3e4a10d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(newsgroups_train.preprocess_data[0])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lerxst wam umd edu thing subject car nntp posting host rac wam umd edu organization university maryland college park lines wondering anyone could enlighten car saw day door sports car looked late early called bricklin doors really small addition front bumper separate rest body know anyone tellme model name engine specs years production car made history whatever info funky looking car please e mail thanks il brought neighborhood lerxst\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно также, что все тексты\n",
        "приведены к нижнему регистру, так и осталось, ну вот, например, слово posting превратилась\n",
        "слова post, слово organization превратилась слова org. То есть в некоторых словах мы обрубили\n",
        "окончании этих слов."
      ],
      "metadata": {
        "id": "dOhmMiDVOsIT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etnaHjcgOzu6"
      },
      "source": [
        "### 2. Перевод текста в вещественное пространство признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk1VkR5IO7oO"
      },
      "source": [
        "#### 2.1 Bag of Words (мешок слов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI8oo_G1PClx"
      },
      "source": [
        "Основное предположение данного метода — порядок слов в документе не важен, \n",
        "\n",
        "а все документы представляются в виде матрицы $ T = (t)_{d,w}$,\n",
        "\n",
        "каждая строка в которой соответствует отдельному документу или тексту, \n",
        "\n",
        "а каждый столбец — определенному слову. \n",
        "\n",
        "Элемент $t_{d,w}$ соответствует количеству вхождений слова $w$ в документ $d$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "А в методе Bag of Words все тексты представляются\n",
        "в виде матрицы, размеры этой матрицы d на w, где d - это количество документов, а w - это\n",
        "количество слов, то есть каждому документу сопоставляется вектор длины, равный общему\n",
        "количеству слов в текстовой выборке. И в i-ой позиции, в i-ой строке j-ом столбце этой\n",
        "матрицы стоит число, которое равно количеству слова j в документе i."
      ],
      "metadata": {
        "id": "AkXenlQdPcyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для того чтобы реализовать Bag of Words воспользуемся из\n",
        "библиотеки sklearn классом CountVectorizer, импортируем этот класс и создадим объект этого класса, а теперь посмотрим\n",
        "как работает CountVectorizer на простом примере."
      ],
      "metadata": {
        "id": "3iEHPdCDT48w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WocMYLbTv9vC"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC_57sTEQBMa"
      },
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aybc8qotQHh8",
        "outputId": "6de25319-0cac-4ceb-c1e2-a29340f8533c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vectorizer.fit(['порядок слов в документе не важен', 'мешок слов'])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим CountVectorizer на 2 документах: в одном\n",
        "первом документе будут слова, порядок слов в документе не важен, во втором документе будут\n",
        "слова, мешок слов. После того как вы обучили объект класса CountVectorizer у него есть метод\n",
        "getfeaturenames. Если вы воспользуетесь этим методом, то вы получите все слова уникальные,\n",
        "которые есть в вашей текстовой выборке. В данном случае у нас есть шесть уникальных слов:"
      ],
      "metadata": {
        "id": "oNQhZuERUP4P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM1spxAeQe3q",
        "outputId": "6ecf504d-5948-4943-eb88-10a2d44178f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vectorizer.get_feature_names()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['важен', 'документе', 'мешок', 'не', 'порядок', 'слов']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь применим метод Bag of Words к каким-то новым текстам. Применим метод Bag of Words\n",
        "к тексту \"важен порядок\" и \"не мешок не порядок\". "
      ],
      "metadata": {
        "id": "spLYYxAWX43L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvG4o-1kQn3z",
        "outputId": "2bdfa5fc-261b-444e-c3fb-d7537a70d15d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vectorizer.transform(['важен порядок', 'не мешок не порядок']).toarray()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 1, 2, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Первому документу соответствует\n",
        "вектор, в котором всего две единицы: первая единица соответствует слову \"важен\", вторая единице соответствует слова порядок вторая\n",
        "единица соответствует слову \"порядок\". Вторая строка соответствует\n",
        "второму документу, и в ней две единицы и одна двойка. Первая единица соответствует\n",
        "слову \"мешок\", вторая единица соответствует слову \"порядок\", а двойка соответствует слову \"не\",\n",
        "потому что слово не встретилось два раза."
      ],
      "metadata": {
        "id": "5B2wJc05ZwC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь напишем функцию Bag of words, которая будет принимать на вход Vectorizer,\n",
        "обучающую и тестовую выборки на обучающей выборке будем применять метод\n",
        "fit.transform, у Vectorizer будем применять fit.transform и в метод fit.transform\n",
        "будем передавать обучающую выборку, а тестовую выборку будем тебе передавать в метод transform.\n",
        "И данная функция будет возвращать полученные Bag of words матрицы для обучающий\n",
        "и для тестовой части."
      ],
      "metadata": {
        "id": "w3dQe9BsaBgx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fednKkjeE-_"
      },
      "source": [
        "def bow(vectorizer, train, test):\n",
        "  train_bow = vectorizer.fit_transform(train)\n",
        "  test_bow = vectorizer.transform(test)\n",
        "  return train_bow, test_bow"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEPL9R0jfUc-"
      },
      "source": [
        "X_train_bow, X_test_bow = bow(vectorizer, \n",
        "                              newsgroups_train.data, \n",
        "                              newsgroups_test.data)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Применим функцию, написанную Bag of words, к обучающей выборке и к тестовой выборке,\n",
        "причем применим к выборкам к текстовым данным, которые не были никак предобработаны.\n",
        "Эти данные лежат по ключу data. Посмотрим на полученные размеры этих матриц.\n",
        "Видно, что полученные размеры этих матриц, полученное признаковое пространство\n",
        "в этих матрицах более 130 тысяч, ну это довольно много. "
      ],
      "metadata": {
        "id": "q6CfFpq2aYQO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaETMkjcfuTv",
        "outputId": "6f9a14ea-7185-4c8c-aa56-4ecb69a06288",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_bow.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXwbJ1OBf1SV",
        "outputId": "ba53d4f5-317a-4b32-c92a-b0eac9d87f87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test_bow.shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7532, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь посмотрим ,что происходит после\n",
        "предобработки данных. Применим функцию Bag of words к предобработанным данным,\n",
        "то есть тем данным, где мы все слова привели к нижнему регистру и удалили там лишние\n",
        "символы, оставили только символы из английского алфавита."
      ],
      "metadata": {
        "id": "0OWm33yrahcv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEfDbzuRgDSY"
      },
      "source": [
        "X_train_bow_preprocess, X_test_bow_preprocess = bow(vectorizer, \n",
        "                                                    newsgroups_train.preprocess_data,\n",
        "                                                    newsgroups_test.preprocess_data)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2BHnhodjIIs",
        "outputId": "4bfd3829-778b-4344-cb69-58798f5f95df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_bow_preprocess.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 88863)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vxGrCfejLVX",
        "outputId": "bac8c1b5-9089-4dcb-f3f2-1b67e9fc5680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test_bow_preprocess.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7532, 88863)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "давайте посмотрим, что будет происходить, когда мы применили стемминг к нашим данным.\n",
        "Признаковое пространство снизилась еще сильнее, размер признаков пространство уже чуть\n",
        "более 61 000, то есть вся эта предобработка текстов, удаление стоп-слов, стемминг, помогает\n",
        "нам снизить размер признакового пространства, и иногда даже повысить качеством работы наших\n",
        "алгоритмов. "
      ],
      "metadata": {
        "id": "uQyhlKeYa06W"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftID74NijN7q"
      },
      "source": [
        "X_train_bow_stem, X_test_bow_stem = bow(vectorizer, \n",
        "                                        newsgroups_train.data_stemming,\n",
        "                                        newsgroups_test.data_stemming)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDErCxTPjgr1",
        "outputId": "dd8703dd-2b28-4820-aa88-f9cfd988a579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_bow_stem.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 61221)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoTAihrHjlnk",
        "outputId": "bd3efb09-5cd9-4b4d-bf4f-d2104d2dfd32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test_bow_stem.shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7532, 61221)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JvGQleCSvHS"
      },
      "source": [
        "#### 2.2 Bag of Words & TF IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Помимо применения метода Bag of Words можно также применять метод Bag of Words\n",
        "& TF IDF преобразование. TF IDF преобразование - это некая статистическая мера, которая равна\n",
        "мере TF умножить на меру IDF. TF - это чистота слова в документе то есть\n",
        "она вычисляется как количество раз которые встретилось слово и делить на\n",
        "общее количество слов внутри данного документа, а IDF помогает уменьшить\n",
        "вес широко употребляемых слов, и IDF вычисляется по формуле логарифм\n",
        "количества документов деленное на количество документов, в которых встретилось\n",
        "данное слово, то есть TF IDF будет большим у тех слов, которые редко встречаются, точнее которые\n",
        "часто встречаются внутри одного документа, но редко встречаются внутри других документов. А будет маленьким либо у слов, которые везде встречаются во всех документах, например, это\n",
        "стоп-слова там, союзы, предлоги, частицы, либо будет маленькое у тех слов, которые очень редко\n",
        "встречаются внутри одного документа."
      ],
      "metadata": {
        "id": "f_AhfrRoe-mh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YSNwHr2SRMh"
      },
      "source": [
        "$TF-IDF$ — это статистическая мера, используемая для оценки\n",
        "\n",
        "важности слова в контексте документа. Вычисляется по формуле:\n",
        "\n",
        "$$TF-IDF(w, d, D) = TF(w, d) × IDF(w, D)$$\n",
        "\n",
        "$TF$ — частота слова, оценивает важность слова $w_i$ в пределах отдельного документа.\n",
        "\n",
        "$$TF(w, d) = \\frac{n_i}{\\sum_k n_k}$$\n",
        "\n",
        "$n_i$ — число вхождений слова $i$ в документ.\n",
        "\n",
        "$\\sum_k n_k$ — общее число слов в данном документе.\n",
        "\n",
        "$IDF$ — обратная частота документа. \n",
        "\n",
        "Учёт $IDF$ уменьшает вес широко употребляемых слов.\n",
        "$$IDF(w, D) = \\log \\frac{|D|}{|w_i \\subset d_i|}, \\text{где}$$\n",
        "\n",
        "$|D|$ — количество документов в корпусе.\n",
        "\n",
        "$|w_i \\subset d_i|$ — количество документов,\n",
        "\n",
        "в которых встречается слово $w_i$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rteG9u1zjovT"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы применить TF преобразования, импортируем класс\n",
        "TfidfVectorizer из библиотеки sklearn и создадим объект этого класса. И вот TfidfVectorizer\n",
        "имеет все те же самые методы, что и CountVectorizer, поэтому\n",
        "мы можем его передавать в уже написанную нами функцию Bag of Words, передадим в функцию\n",
        "Bag of Words TfidfVectorizer и так же посмотрим, что будет происходить."
      ],
      "metadata": {
        "id": "j69NQkWBgsom"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKZDpujwkIdK"
      },
      "source": [
        "vectorizer_tf_idf = TfidfVectorizer()"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlDqTbIFkSq2"
      },
      "source": [
        "X_train_tfidf, X_test_tfidf = bow(vectorizer_tf_idf, \n",
        "                                  newsgroups_train.data, \n",
        "                                  newsgroups_test.data)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала передадим данные, в которых не было предобработки, передадим данные,\n",
        "в которых была простая предобработка, то есть удаление лишних символов, приведение к\n",
        "нижнему регистру, удаление стоп-слов и применим к данным, в которых мы еще применяли\n",
        "стемминг. "
      ],
      "metadata": {
        "id": "zMrSkkBdhTCt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JTYu0JEkqVi"
      },
      "source": [
        "X_train_tfidf_preprocess, X_test_tfidf_preprocess = bow(vectorizer_tf_idf,\n",
        "                                                        newsgroups_train.preprocess_data,\n",
        "                                                        newsgroups_test.preprocess_data)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zmpdGT1lIWL"
      },
      "source": [
        "X_train_tfidf_stem, X_test_tfidf_stem = bow(vectorizer_tf_idf,\n",
        "                                            newsgroups_train.data_stemming,\n",
        "                                            newsgroups_test.data_stemming)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также иногда\n",
        "помимо учета каждого слова необходимо еще учитывать\n",
        "и n-граммы слов, так как иногда слова поодиночке не несут никакой информации о тексте."
      ],
      "metadata": {
        "id": "p31yANkziUQM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u-SKgBXlbRq"
      },
      "source": [
        "vectorizer_ngram = TfidfVectorizer(ngram_range=(1,2))"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем учитывать n-граммы длины 2, то есть биграммы, помимо каждого слова по отдельности\n",
        "будем еще учитывать и биграммы. Также используем функцию Bag of force и передадим туда\n",
        "Vectoraizer, в котором мы использовали биграммы, и применим это все к данным, к которым был\n",
        "применён стемминг. Посмотрим, как изменяется размерность признакового пространства\n",
        "при использовании n-грамм. Видно, что размерность признакового пространства очень\n",
        "сильно возросла. Но использование биграмм может повысить качество работы\n",
        "нашего алгоритма. "
      ],
      "metadata": {
        "id": "V33B0hMPis08"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFKYG1uRmZgV"
      },
      "source": [
        "X_train_ngram_stem, X_test_ngram_stem = bow(vectorizer_ngram, \n",
        "                                            newsgroups_train.data_stemming,\n",
        "                                            newsgroups_test.data_stemming)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4xEOvcanTgN",
        "outputId": "d7ea5c35-060a-4bf5-fda3-9aa2b104019d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_ngram_stem.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 934463)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq4oBoQwnaU-",
        "outputId": "e9a08a85-5e42-4386-8132-2f3d34cf353b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test_ngram_stem.shape"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7532, 934463)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdeFw_f58fw4"
      },
      "source": [
        "### 3. Выбор алгоритма машинного обучения для классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь приступим к следующему этапу задачи классификации\n",
        "текстов, а именно выберем алгоритм машинного обучения для классификации и замерим качество\n",
        "его работы."
      ],
      "metadata": {
        "id": "KRcDwvH_jV1z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhRQvNYLndMl"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как полученное признаковое пространство с помощью метода Bag of Words имеет\n",
        "высокую размерность, то будем использовать линейные алгоритмы классификации, будем использовать\n",
        "логистическую регрессию и SVM. Импортируем логистическую регрессию и SVM, а также необходимые\n",
        "методы и создадим объект класса логистической регрессии с параметрами по умолчанию, и создадим\n",
        "объект класса LinearSVC, тоже с параметрами по умолчанию. "
      ],
      "metadata": {
        "id": "jO7HmCINjfCc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47mZPCNrZzMk"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doizgpm8TJGl"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf_svc = LinearSVC()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "На прошлом этапе мы получили много\n",
        "матриц объекты-признаки для разных данных: для не предобработанных данных, для предобработанных\n",
        "данных, для данным со стеммингом, а также для данных с n-граммами, с биграммами точнее.\n",
        "И теперь запустим логистическую регрессию и SVM на всех этих данных, и посмотрим какое будет качество."
      ],
      "metadata": {
        "id": "PVKXSiwfjyOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необработанные"
      ],
      "metadata": {
        "id": "eyrrh18hj3h6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxB4gQxUZzG4",
        "outputId": "7aa189ce-19ba-41f1-b1a3-c0d2b021c9e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf.fit(X_train_bow, newsgroups_train.target)\n",
        "print ('LogisticRegression: ',\n",
        "       accuracy_score(clf.predict(X_test_bow), newsgroups_test.target))\n",
        "\n",
        "clf_svc.fit(X_train_bow, newsgroups_train.target)\n",
        "print ('LinearSVC: ',\n",
        "       accuracy_score(clf_svc.predict(X_test_bow), newsgroups_test.target))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression:  0.7858470525756771\n",
            "LinearSVC:  0.7857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У неё получалось: Видно, что на не предобработанных данных доля правильных ответов у\n",
        "логистической регрессии чуть более 0,80, у SVM - чуть более 0,78."
      ],
      "metadata": {
        "id": "qL9SMGfekRVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Простая обработка: мы применили предобработку, то есть мы снизили размерность признакового\n",
        "пространства, привели все слова к нижнему регистру, удалили лишние символы и удалили стоп-слова"
      ],
      "metadata": {
        "id": "51KqntWMj5m6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e9N2wHqZzAo",
        "outputId": "d1170c28-b545-4bac-83f2-0590d444d351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf.fit(X_train_bow_preprocess, newsgroups_train.target)\n",
        "print ('LogisticRegression: ',\n",
        "       accuracy_score(clf.predict(X_test_bow_preprocess),\n",
        "                      newsgroups_test.target))\n",
        "\n",
        "clf_svc.fit(X_train_bow_preprocess, newsgroups_train.target)\n",
        "print ('LinearSVC: ',\n",
        "       accuracy_score(clf_svc.predict(X_test_bow_preprocess),\n",
        "                      newsgroups_test.target))\n",
        "\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression:  0.8017790759426447\n",
            "LinearSVC:  0.7927509293680297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь\n",
        "качество работы и линейной регрессии, и svm чуть выше, качество работы, доля правильных\n",
        "ответов линейной регрессии уже более 0,81, а SVM более 0,79."
      ],
      "metadata": {
        "id": "nCTiRjj7klJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стемминг"
      ],
      "metadata": {
        "id": "xrsEngtHj9H7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjNzmA3eZy7O",
        "outputId": "38f270cb-b63b-4ea5-aecb-32224a4ebc3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf.fit(X_train_bow_stem, newsgroups_train.target)\n",
        "print ('LogisticRegression: ',\n",
        "       accuracy_score(clf.predict(X_test_bow_stem),\n",
        "                      newsgroups_test.target))\n",
        "\n",
        "clf_svc.fit(X_train_bow_stem, newsgroups_train.target)\n",
        "print ('LinearSVC: ',\n",
        "       accuracy_score(clf_svc.predict(X_test_bow_stem),\n",
        "                      newsgroups_test.target))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression:  0.7972650026553372\n",
            "LinearSVC:  0.781465746149761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "После применения стемминга\n",
        "и у логистической регрессии, и у SVM качество немного упало, но зато мы смогли значительно\n",
        "снизить размерность нашего признакового пространства, иногда это бывает очень важная задача. "
      ],
      "metadata": {
        "id": "G9jMuB46kuyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF"
      ],
      "metadata": {
        "id": "ZYRQ4aDZkvoL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz9GwO-NZyyg",
        "outputId": "19afb5fc-4556-4440-a674-1d3ff196c7ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf.fit(X_train_tfidf, newsgroups_train.target)\n",
        "print ('LogisticRegression: ',\n",
        "       accuracy_score(clf.predict(X_test_tfidf), newsgroups_test.target))\n",
        "\n",
        "clf_svc.fit(X_train_tfidf, newsgroups_train.target)\n",
        "print ('LinearSVC: ',\n",
        "       accuracy_score(clf_svc.predict(X_test_tfidf), newsgroups_test.target))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression:  0.8274030801911842\n",
            "LinearSVC:  0.8531598513011153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У логистической регрессии на не предобработанных данных качество уже выше,\n",
        "более 0,82, а у SVM качество еще значительно выше - более 0,85, то есть TF IDF\n",
        "преобразование, с помощью TF IDF преобразования нам удалось значительно улучшить качество работы\n",
        "нашего алгоритма."
      ],
      "metadata": {
        "id": "epy9harnlEjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь посмотрим на то же самое, но уже на предобработанных данных, то есть данных,\n",
        "к которым была применена предобработки, а затем применено TF преобразование. "
      ],
      "metadata": {
        "id": "0HR4GzPrlIT8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTVeqc4GZyei",
        "outputId": "6913e026-640f-4c20-a239-f9643e130fa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf.fit(X_train_tfidf_preprocess, newsgroups_train.target)\n",
        "print ('LogisticRegression: ',\n",
        "        accuracy_score(clf.predict(X_test_tfidf_preprocess), \n",
        "                       newsgroups_test.target))\n",
        "\n",
        "clf_svc.fit(X_train_tfidf_preprocess, newsgroups_train.target)\n",
        "print ('LinearSVC: ',\n",
        "        accuracy_score(clf_svc.predict(X_test_tfidf_preprocess), \n",
        "                       newsgroups_test.target))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression:  0.8323154540626659\n",
            "LinearSVC:  0.8509028146574615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "И здесь качество\n",
        "у логистической регрессии возрастает, более 0,83, а у SVM там незначительно падает, чуть более\n",
        "0,85. "
      ],
      "metadata": {
        "id": "XeaDm_FNlYrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Замерим качества, которые будут у данных, к которым применили стемминг."
      ],
      "metadata": {
        "id": "QuEmuhF1lgsy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsWsVay6Zyax",
        "outputId": "c3f89117-ddd8-486f-c0e7-5f82630c1532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf.fit(X_train_tfidf_stem, newsgroups_train.target)\n",
        "print ('LogisticRegression: ',\n",
        "       accuracy_score(clf.predict(X_test_tfidf_stem), \n",
        "                      newsgroups_test.target))\n",
        "\n",
        "clf_svc.fit(X_train_tfidf_stem, newsgroups_train.target)\n",
        "print ('LinearSVC: ',\n",
        "       accuracy_score(clf_svc.predict(X_test_tfidf_stem),\n",
        "                      newsgroups_test.target))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression:  0.825942644715879\n",
            "LinearSVC:  0.8437334041423261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь качество немного упало, у логистической регрессии немного более 0,82, у SVM чуть\n",
        "более 0,84."
      ],
      "metadata": {
        "id": "S5lPrdLtlm_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также посмотрим на качества, которые удалось получить на данных, в которых\n",
        "использовались еще n-граммы."
      ],
      "metadata": {
        "id": "Md0e8OOQld_2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpIlTWoYZyYU",
        "outputId": "a8ed0efa-038f-4d4a-c0da-c3144467a837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf.fit(X_train_ngram_stem, newsgroups_train.target)\n",
        "print ('LogisticRegression: ',\n",
        "       accuracy_score(clf.predict(X_test_ngram_stem), \n",
        "                      newsgroups_test.target))\n",
        "\n",
        "clf_svc.fit(X_train_ngram_stem, newsgroups_train.target)\n",
        "print ('LinearSVC: ',\n",
        "       accuracy_score(clf_svc.predict(X_test_ngram_stem),\n",
        "                      newsgroups_test.target))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression:  0.8295273499734467\n",
            "LinearSVC:  0.8555496548061604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этих данных было очень большое, очень большая размерность\n",
        "признакового пространство, там было более 900 000 признаков, но зато нам удалось достичь\n",
        "хорошего качества с помощью метода SVM. Ну и тоже неплохое качество с помощью логистической\n",
        "регрессии."
      ],
      "metadata": {
        "id": "V3Ysd15Cl5QG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данной задачи SVM показал качество лучше, чем логистическая регрессия, это можно\n",
        "объяснить его особенностью функций потерь, которая не поощряет растить отступы, и часто SVM работает,\n",
        "показывает качество выше по метрике accuracy, чем в логистической регрессии. "
      ],
      "metadata": {
        "id": "DfFRKWjql-Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "еперь рассмотрим\n",
        "тексты, на которых ошиблась построенная нами модель. Для этого посмотрим на матрицу ошибок,\n",
        "импортируем функцию для построения матрицы ошибок и построим эту матрицу. "
      ],
      "metadata": {
        "id": "IRNSlUMhmNuX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJHWFcawjVKd"
      },
      "source": [
        "import seaborn\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcuEWD2IjVII"
      },
      "source": [
        "predict_targets = clf_svc.predict(X_test_ngram_stem)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuCopDNujVDM",
        "outputId": "a9b949b7-b52f-4319-9536-6fc03cab3802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "seaborn.heatmap(confusion_matrix(newsgroups_test.target, predict_targets))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1775bdf390>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из матрицы ошибок видно,\n",
        "что построенный нами алгоритм путает 18 и 16 класс. "
      ],
      "metadata": {
        "id": "GHrd9-vVmR-W"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sSdHDPjjVAv",
        "outputId": "f6381add-64a6-432a-8d0f-8ffbc3488193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "newsgroups_test.target_names[18]"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrluANXdjU9Q",
        "outputId": "d4a60b01-9fce-4596-c314-eab2d713fc84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "newsgroups_test.target_names[16]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.politics.guns'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте посмотрим на названия этих классов.\n",
        "Видно, что 18 класс о политике и 16 класс тоже о политике, но другая подгруппа политики. То есть наш\n",
        "алгоритм часто путает 2 класса, которые посвящены политике, на видимо в них встречаются какие-то\n",
        "схожие слова. "
      ],
      "metadata": {
        "id": "LXHWNQ53mcCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "И посмотрим на тексты, на какие-то случайные тексты, в которых ошиблась наша модель.\n",
        "Вот мы рассмотрели два текста: первый текст о политике, второй текст тоже о политике. Видно, что\n",
        "рассматриваемые тексты короткие, и в них встречались слова, которые\n",
        "относятся к политике, и наша модель просто перепутала эти тексты"
      ],
      "metadata": {
        "id": "VZGC_lcLpAjq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npSRo-HajUye",
        "outputId": "e0d386e0-8608-478d-802e-e8b8ff9ecb28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ind = np.where(newsgroups_test.target != predict_targets)\n",
        "ind = ind[0]\n",
        "random_ind = np.random.randint(0,ind.shape[0],(2))\n",
        "for i in random_ind:\n",
        "    img=newsgroups_test.data[ind[i]]\n",
        "    print ('Правильный класс: ', \n",
        "           newsgroups_test.target_names[newsgroups_test.target[ind[i]]])\n",
        "    print ('Предсказанный класс: ', \n",
        "           newsgroups_test.target_names[predict_targets[ind[i]]])\n",
        "    print(img)\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Правильный класс:  talk.religion.misc\n",
            "Предсказанный класс:  sci.med\n",
            "From: geb@cs.pitt.edu (Gordon Banks)\n",
            "Subject: Re: [lds] Birth of a Church\n",
            "Reply-To: geb@cs.pitt.edu (Gordon Banks)\n",
            "Organization: Univ. of Pittsburgh Computer Science\n",
            "Lines: 22\n",
            "\n",
            "In article <C5x97x.1EA@acsu.buffalo.edu> psyrobtw@ubvmsb.cc.buffalo.edu (Robert Weiss) writes:\n",
            ">\n",
            ">\"No church will admit that I am right except  the  one  with  which  I  am\n",
            ">associated. This makes them witnesses against each other, and  how  can  I\n",
            ">decide in such a case as this, seeing they are all unlike  the  Church  of\n",
            ">Christ, as it existed in former days!\" (p. 31).\n",
            ">\n",
            "\n",
            "The idea of an apostacy did not originate with Lucy Smith or Joseph\n",
            "Smith or the Mormons.  The idea of a restoration was quite common\n",
            "in the early 19th century USA.  Alexander Campbell, founder of the\n",
            "group that now survives with the name \"Disciples of Christ\" preached\n",
            "that the primitive church had been lost and was attempting to restore\n",
            "it (although not be revelations).  Many Cambellites subsequently became\n",
            "Mormons, including co-founder Sidney Rigdon.  Actually, you can find\n",
            "such sentiments in many of the early protestants of the reformation,\n",
            "such as Martin Luther.\n",
            "-- \n",
            "----------------------------------------------------------------------------\n",
            "Gordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and\n",
            "geb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\" \n",
            "----------------------------------------------------------------------------\n",
            "\n",
            "Правильный класс:  sci.crypt\n",
            "Предсказанный класс:  comp.graphics\n",
            "From: schlege@lips.ecn.purdue.edu (Kevin L Schlegelmilch)\n",
            "Subject: Source code for Substitution cipher\n",
            "Organization: Purdue University Engineering Computer Network\n",
            "Lines: 7\n",
            "\n",
            "  I was wondering if anyone knew of where I could find source\n",
            "code for a program to solve a substitution cipher?  \n",
            "\n",
            "Thanks!\n",
            "Kevin\n",
            "\n",
            "(Please post your answer instead of e-mailing me directly)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buFTE7SdjUs3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ_DUOFsZyUu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}